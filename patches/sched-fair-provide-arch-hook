Bottom: 9020eef783e3fa58829014e8b3110202b8ec8480
Top:    fe40956ff18833a58449efad7a32a4d0626b13db
Author: Parth Shah <parth@linux.ibm.com>
Date:   2019-10-07 14:00:50 +0530

sched/fair: Provide arch hook to find domain for non idle core search scan

Specify the method which returns cpumask within which to limit the
search for a non idle core. By default, limit the search in LLC domain
which usually includes few/all the cores in the processor chip.

The select_non_idle_core searches for the non idle cores in the LLC domain.
But in the systems with multiple NUMA domains, the Turbo frequency can be
sustained within the NUMA domain without being affected from other
NUMA. For such case, arch_turbo_domain can be tuned to change domain for
non idle core search.

Signed-off-by: Parth Shah <parth@linux.ibm.com>


---

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 0de3873c0a27..d52473794047 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5886,6 +5886,14 @@ static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int t
 }
 
 #ifdef CONFIG_SCHED_SMT
+
+#ifndef arch_turbo_domain
+static __always_inline struct cpumask *arch_turbo_domain(int cpu)
+{
+	return sched_domain_span(rcu_dereference(per_cpu(sd_llc, cpu)));
+}
+#endif
+
 static inline bool is_background_task(struct task_struct *p)
 {
 	if (p->flags & PF_CAN_BE_PACKED)
@@ -5910,7 +5918,8 @@ static int select_non_idle_core(struct task_struct *p, int prev_cpu, int target)
 	struct cpumask *cpus = this_cpu_cpumask_var_ptr(turbo_sched_mask);
 	int iter_cpu, sibling;
 
-	cpumask_and(cpus, cpu_online_mask, p->cpus_ptr);
+	cpumask_and(cpus, cpu_online_mask, arch_turbo_domain(prev_cpu));
+	cpumask_and(cpus, cpus, p->cpus_ptr);
 
 	for_each_cpu_wrap(iter_cpu, cpus, prev_cpu) {
 		int idle_cpu_count = 0, non_idle_cpu_count = 0;
