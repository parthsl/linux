Bottom: 666c6dc87bff9aa7acd6ec7b9e0eab07f0a7bd35
Top:    fcea1ac0117af724cdd74030c543ff1778384c5b
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-05-04 15:26:40 +0530

sched/idle: Add debugging bits to validate inconsistency in latency
sensitive task calculations

We monitor the task entering/exiting the scheduler, but there might be
unhandled situations which can lead to inconsistent value of the
nr_lat_sensitive counter. This may lead to restricting the use of IDLE
states despite absence of any latency sensitive workload.
Hence, add pr_info() if a negative value of nr_lat_sensitive value is found.

Signed-off-by: Parth Shah <parth@linux.ibm.com>


---

diff --git a/kernel/sched/idle.c b/kernel/sched/idle.c
index 85d72a6e2521..7aa0775e69c0 100644
--- a/kernel/sched/idle.c
+++ b/kernel/sched/idle.c
@@ -231,6 +231,11 @@ static void cpuidle_idle_call(void)
 static void do_idle(void)
 {
 	int cpu = smp_processor_id();
+	int pm_disabled = per_cpu(nr_lat_sensitive, cpu);
+
+	if (pm_disabled < 0)
+		pr_info("Inconsistent value of nr_lat_sensitive counter\n");
+
 	/*
 	 * If the arch has a polling bit, we maintain an invariant:
 	 *
@@ -263,7 +268,7 @@ static void do_idle(void)
 		 * idle as we know that the IPI is going to arrive right away.
 		 */
 		if (cpu_idle_force_poll || tick_check_broadcast_expired() ||
-		    per_cpu(nr_lat_sensitive, cpu)) {
+		    pm_disabled) {
 			tick_nohz_idle_restart_tick();
 			cpu_idle_poll();
 		} else {
