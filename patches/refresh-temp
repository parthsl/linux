Bottom: 3525144993da9748807c5ff324fdd7662cd08d6d
Top:    95ad21949183eeb7d4e344f09431274d7a8174a2
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-01-16 17:52:14 +0530

Refresh of sched-fair-tune-task-wake-up

---

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index f038f65ed006..6ce6d9803e52 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5887,11 +5887,12 @@ static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int t
 
 #ifdef CONFIG_SCHED_SMT
 
-/* Define non-idle CPU/task as the one with the utilization >= 12.5% */
-#define is_zealous(util) ((util) > (100 >> 3))
+/* Define non-idle CPU as the one with the utilization >= 12.5% */
+#define is_cpu_non_idle(util) ((util) > (100 >> 3))
 
 static inline bool is_background_task(struct task_struct *p)
 {
+	/* Pack a task with utilization >= 12.5% only */
 	if (task_latency_lenient(p) && (task_util(p) > (1024 >> 3)))
 		return true;
 
@@ -5928,7 +5929,7 @@ static int select_non_idle_core(struct task_struct *p, int prev_cpu)
 				non_idle_cpu_count++;
 				if (cpu_overutilized(sibling))
 					overutil_cpu_count++;
-				if (is_zealous(cpu_util(sibling)))
+				if (is_cpu_non_idle(cpu_util(sibling)))
 					busy_cpu_count++;
 			}
 		}
