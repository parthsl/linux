Bottom: 281b8c1e69a79d43f4be52d232e0f51c7cb37371
Top:    2f69df15228d3c90487335e2a3681027a4a470b8
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-01-29 12:03:25 +0530

Refresh of sched-fair-tune-task-wake-up

---

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 26c6e61b1182..a189a9d2a23e 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5889,7 +5889,7 @@ static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int t
 #ifdef CONFIG_SCHED_SMT
 
 /* Define non-idle CPU as the one with the utilization >= 12.5% */
-#define merely_used_cpu(util) ((cpu_util(util)) > (100 >> 3))
+#define busy_cpu(util) ((cpu_util(util)) > (100 >> 3))
 
 /*
  * Classify small background tasks with higher latency_nice value for task
@@ -5933,7 +5933,7 @@ static int select_non_idle_core(struct task_struct *p, int prev_cpu)
 				non_idle_cpu_count++;
 				if (cpu_overutilized(sibling))
 					overutil_cpu_count++;
-				if (merely_used_cpu(sibling))
+				if (busy_cpu(sibling))
 					busy_cpu_count++;
 			}
 		}
