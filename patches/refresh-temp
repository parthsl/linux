Bottom: 0e639ad17117e9c7f1ca1f605ff7d98663389180
Top:    d1daff64a4f75738e31ae3157a0d0b2a258a4613
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-05-13 15:19:42 +0530

Refresh of sched-allow-sched_-get-set

---

diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 6031ec58c7ae..44bcbf060718 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -4731,9 +4731,6 @@ static void __setscheduler_params(struct task_struct *p,
 	p->rt_priority = attr->sched_priority;
 	p->normal_prio = normal_prio(p);
 	set_load_weight(p, true);
-
-	if (attr->sched_flags & SCHED_FLAG_LATENCY_NICE)
-		p->latency_nice = attr->sched_latency_nice;
 }
 
 /* Actually do priority change: must hold pi & rq lock. */
@@ -4749,6 +4746,13 @@ static void __setscheduler(struct rq *rq, struct task_struct *p,
 
 	__setscheduler_params(p, attr);
 
+	/*
+	 * Change latency_nice value only when SCHED_FLAG_LATENCY_NICE or
+	 * SCHED_FLAG_ALL sched_flag is set.
+	 */
+	if (attr->sched_flags & SCHED_FLAG_LATENCY_NICE)
+		p->latency_nice = attr->sched_latency_nice;
+
 	/*
 	 * Keep a potential priority boosting if called from
 	 * sched_setscheduler().
