Bottom: 826460f014ffae1f2da9b608b972ea4e695686c2
Top:    60b7b699d2adf7d582979763f65b380cc0fec16b
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-05-06 14:00:10 +0530

Refresh of sched-idle-add-debugging-bits

---

diff --git a/kernel/sched/idle.c b/kernel/sched/idle.c
index 579817ca3fdf..c7a8533a8876 100644
--- a/kernel/sched/idle.c
+++ b/kernel/sched/idle.c
@@ -233,8 +233,6 @@ static void do_idle(void)
 	int cpu = smp_processor_id();
 	int pm_disabled = atomic_read(&per_cpu(nr_lat_sensitive, cpu));
 
-	WARN_ON(pm_disabled < 0);
-
 	/*
 	 * If the arch has a polling bit, we maintain an invariant:
 	 *
@@ -260,6 +258,9 @@ static void do_idle(void)
 
 		arch_cpu_idle_enter();
 
+		if (pm_disabled < 0)
+			pr_info("Inconsistent value set for nr_lat_sensitive");
+
 		/*
 		 * In poll mode we reenable interrupts and spin. Also if we
 		 * detected in the wakeup from idle path that the tick
