Bottom: 6e9b0e489365dcfdfff0351547957293af7e210e
Top:    0bc891bba1c1b53dc3476e21c971f445195bb3b8
Author: Parth Shah <parth@linux.ibm.com>
Date:   2020-02-11 11:16:09 +0530

Refresh of sched-fair-allow-pre-empted

---

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 9abd9085708a..95c20c4e8061 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -5912,7 +5912,7 @@ static int select_idle_cpu(struct task_struct *p, struct sched_domain *sd, int t
 
 	for_each_cpu_wrap(cpu, cpus, target) {
 		if (!--nr)
-			return -1;
+			break;
 		ict = is_idle_cpu(cpu);
 		if (ict >= cpu_non_preempted_idle)
 			break;
